import whisper
from openai import AzureOpenAI
import sys
import os
import requests

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../Project_Backend")))
from speechToText.speechDAO import SpeechDAO

dao = SpeechDAO()

# ê²½ë¡œ í™•ì¸ (ì„ íƒ ì‚¬í•­)
audio_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../ai/whisper_gpt/audioSample.mp3"))
# ëª¨ë¸ ë¡œë”©
model = whisper.load_model("base")  # ì„±ëŠ¥ ë”°ë¼ ë‹¤ë¥¸ ëª¨ë¸ ì„ íƒ ê°€ëŠ¥

# í…ìŠ¤íŠ¸ ì¶”ì¶œ
TxtResult = model.transcribe(audio_path, language="ko")

# ì¶œë ¥
print("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:")
print(TxtResult["text"])

#################################################################

client = AzureOpenAI(
    azure_endpoint="https://team01-05-4067-resource.openai.azure.com/",  # Azure OpenAI ì—”ë“œí¬ì¸íŠ¸
     # ğŸ”’ ì—¬ê¸°ì— Azure OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤
    api_version="2024-12-01-preview", 
)

conversation = [{
    "role": "system",
    "content": (
        "ë„ˆëŠ” ì‹ ê³  ë‚´ìš©ì„ ë‹¤ìŒ ì„¸ í•­ëª©ìœ¼ë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•˜ëŠ” ë„ìš°ë¯¸ì•¼.\n"
        "1. ì¥ì†Œ\n2. ê³µê³µê¸°ë¬¼ ì¢…ë¥˜\n3. ë°œê²¬ëœ ë¬¸ì œ ë˜ëŠ” ì ê²€ í•„ìš” ì‚¬ìœ \n"
        "ê° í•­ëª©ì€ í•œ ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , ë¶ˆí•„ìš”í•œ ë¬¸ì¥ì€ ì¶”ê°€í•˜ì§€ ë§ˆ."
    )
}]

userInput = TxtResult["text"]
conversation.append({"role": "user", "content": userInput})
res = client.chat.completions.create(
        model="gpt-4.1",
        messages=conversation,
        extra_body={
            "data_sources": [
                {
                    "type": "azure_search",
                    "parameters": {
                        "endpoint": "https://ainuri-search.search.windows.net",  # Azure Cognitive Search ì—”ë“œí¬ì¸íŠ¸
                        "index_name": "ainuri-index",
                        "authentication": {
                            # ì˜ì–´ë¡œ "íƒ€ì…" :"ì—ì´í”¼ì•„ì´ í‚¤"
                             # ğŸ”’ ì—¬ê¸°ì— Azure Search Admin Keyë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤
                        },
                        "embedding_dependency": {
                            "type": "endpoint",
                            "endpoint": "https://team01-05-4067-resource.cognitiveservices.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview",
                            "authentication": {
                                # ì˜ì–´ë¡œ "íƒ€ì…" :"ì—ì´í”¼ì•„ì´ í‚¤"
                                  # ğŸ”’ ì—¬ê¸°ì— Azure OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤
                            },
                        },
                    },
                }
            ]
        },
    )

reportResult = res.choices[0].message.content
parsed = dao.parse_report_result(reportResult)
print("---------------------")
print("gpt êµ¬ì¡°í™” ")
print(reportResult)
print("---------------------")
print(parsed)

# â‘¢ FastAPIë¡œ GET ìš”ì²­ ë³´ë‚´ê¸°
params = {
    "location": parsed["ì¥ì†Œ"],
    "type": parsed["ê³µê³µê¸°ë¬¼ ì¢…ë¥˜"],
    "problem": parsed["ë°œê²¬ëœ ë¬¸ì œ ë˜ëŠ” ì ê²€ í•„ìš” ì‚¬ìœ "]
}

response = requests.get("http://localhost:9999/info.speechToText", params=params)

# â‘£ ì‘ë‹µ í™•ì¸
print("---------------------")
print("FastAPI ì‘ë‹µ ê²°ê³¼:")
print(response.json())